
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as pyplot
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn import metrics as mt
import matplotlib.pyplot as plt

### The first two lines of the code load an image and display it using the st.image function
image = Image.open('gtao.png')
st.image(image)

### The st.sidebar function creates a sidebar and adds a header and a markdown line. The app_mode variable is created to hold the selected option from the dropdown menu.
st.sidebar.header("Dashboard")
st.sidebar.markdown("---")
app_mode = st.sidebar.selectbox('üîé Select Page',['Introduction','Visualization','Prediction'])

if app_mode == 'Introduction': 
### The select_dataset variable is created to hold the selected dataset from the dropdown menu. The pd.read_csv function is used to read the data from a CSV file.
  select_dataset =  st.sidebar.selectbox('üíæ Select Dataset',["Recorded_stats"])
  df = pd.read_csv("recorded_stats.csv")
  st.title("Grand Theft Auto Online Dashboard - 01 Introduction Page üîé")

  ### The st.markdown function is used to display some text and headings on the web application.
  st.markdown("### 00 - Show  Dataset")

  ### The st.number_input function creates a widget that allows the user to input a number. The st.radio function creates a radio button widget that allows the user to select either "Head" or "Tail".
  num = st.number_input('No. of Rows', 5, 10)
  head = st.radio('View from top (head) or bottom (tail)', ('Head', 'Tail'))
  if head == 'Head':
  ### the st.dataframe function displays the data frame.
    st.dataframe(df.head(num))
  else:
    st.dataframe(df.tail(num))

  st.markdown("Number of rows and columns helps us to determine how large the dataset is.")
  ### The st.text and st.write functions display the shape of the data frame and some information about the variables in the data set.
  st.text('(Rows,Columns)')
  st.write(df.shape)

  st.markdown("##### Variables ‚û°Ô∏è")
  st.markdown(" **account_id**: Unique account ID tied to the platform")
  st.markdown(" **platform_id**: Platform indicator (PC,PS4,XBOX)")
  st.markdown(" **occur_date**: Date in field in the format YYYY-MM-DD (day of occurence")
  st.markdown(" **activity_type**: Broad activity category (Heist, Races, Biker Missions,...)")
  st.markdown(" **time_spent**: Time spent in the activity (hours)")
  st.markdown(" **kills**: Number of kills during activity")
  st.markdown(" **deaths**: Number of deaths during activity")
  st.markdown(" **suicides**: Number of suicides during activity")
  st.markdown(" **money_earned**: GTA$ earned in activity ")
  st.markdown(" **rp_earned**: RP (experience) earned in activity")
  st.markdown(" **success**: Indicator of a sucessful activity conclusion")
  st.markdown(" **item**: Item name as seen in game")
  st.markdown(" **item_type**: Item type descriptor (vehicle, property, weapon)")
  st.markdown(" **item_sub_type**: Secondary item descriptor (car, helicopter, garage,...")
  st.markdown(" **money_spent**: GTA$ spent")

  ### The st.markdown and st.dataframe functions display the descriptive statistics of the data set.
  st.markdown("### 01 - Description")
  st.dataframe(df.describe())

  ### The st.markdown, st.write, and st.warning functions are used to display information about the missing values in the data set.
  st.markdown("### 02 - Missing Values")
  st.markdown("Missing values are known as null or NaN values. Missing data tends to **introduce bias that leads to misleading results.**. Original dataset from Rockstar North Limited - development studio of Grand Theft Auto Online game")
  dfnull = df.isnull().sum()/len(df)*100
  totalmiss = dfnull.sum().round(2)
  st.write("Percentage of total missing values:",totalmiss)
  st.write(dfnull)
  if totalmiss <= 30:
    st.success("Looks good! as we have less then 30 percent of missing values.")
  else:
    st.warning("Poor data quality due to greater than 30 percent of missing value.")
    st.markdown(" > Theoretically, 25 to 30 percent is the maximum missing values are allowed, there's no hard and fast rule to decide this threshold. It can vary from problem to problem.")

if app_mode == "Prediction":

  ### The st.title() function sets the title of the Streamlit application to "Mid Term Template - 03 Prediction Page üß™".
  st.title("Grand Theft Auto Online Dashboard - 03 Prediction Page üîã")
  org_df = pd.read_csv("recorded_stats.csv")
  df = org_df.dropna()

  ### Create a tab for users to choose model
  model_type = st.sidebar.selectbox('üîé Select Model',['Tree Classifier','K_Nearest_Neighbor'])

  ### The st.sidebar.number_input() function creates a number input widget in the sidebar that allows users to select the size of the training set.
  test_size = st.sidebar.number_input("Test Set Size", min_value=0.00, step=0.01, max_value=1.00, value=0.30)
  
  if model_type == 'Tree Classifier':
    ### The st.sidebar.selectbox() function creates a dropdown menu in the sidebar that allows users to select the target variable to predict.
    list_variables = ['success']
    select_variable =  st.sidebar.selectbox('üéØ Select Variable to Predict',list_variables)

    new_df= df.drop(labels=select_variable, axis=1)  #axis=1 means we drop data by columns
    list_var = new_df.columns

    ### View of dataset
    st.write("Dataset")
    st.write(df)

    ### The st.multiselect() function creates a multiselect dropdown menu that allows users to select the explanatory variables.
    output_multi = st.multiselect("Select Explanatory Variables", list_var, default=['time_spent','kills','money_earned','rp_earned'])
  
    new_df2 = new_df[output_multi]
    x = new_df2
    y = df['success']

    ### The train_test_split() function splits the data into training and testing sets.
    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=test_size)
    ### Create Decision Tree classifer object
    clf = DecisionTreeClassifier()

    ### The clf.fit() function fits the Decision Tree model to the training data.
    clf.fit(X_train,y_train)

    ###The clf.predict() function generates predictions for the testing data.
    #Predict the response for test dataset
    y_pred = clf.predict(X_test)

    ### The st.columns() function creates 3 columns to display the feature columns and target column.
    col1,col2 = st.columns(2)
    col1.subheader("Variables used")
    col1.write(X_test.head(10))
    col2.subheader("Selling price comparision")

    ###Concat 2 columns, covert predictions type from array to df
    df_pred = pd.concat([pd.DataFrame(y_pred),y_test],ignore_index=True,axis=1) 
    df_pred.columns = ['Prediction','Real data']
    col2.write(df_pred.head(10))

    ### The st.subheader() function creates a subheading for the results section.
    st.subheader('üéØ Results')
    st.write("1) The Accuracy score of model is:", np.round(mt.accuracy_score(y_test, y_pred),2))
    st.write("2) Confusion matrix")

    ###Confusion matrix
    from sklearn.metrics import confusion_matrix
    conf_matrix = confusion_matrix(y_test, y_pred)

    from sklearn.metrics import ConfusionMatrixDisplay
    fig, ax = plt.subplots(figsize=(8,6), dpi=50)
    display = ConfusionMatrixDisplay(conf_matrix)
    ax.set(title='Confusion Matrix for Success Prediction Model')
    display.plot(ax=ax)
    st.pyplot(fig)

  else:
    ### create a sidebar for n_neighbor number
    n_number = st.sidebar.number_input("N_neighbor", min_value= 0, step= 1, max_value= 40, value= 4)

    ### The st.sidebar.selectbox() function creates a dropdown menu in the sidebar that allows users to select the target variable to predict.
    list_variables = ['activity_type']
    select_variable =  st.sidebar.selectbox('üéØ Select Variable to Predict',list_variables)

    ###Drop text columns
    df.drop(df[['account_id','platform_id','occur_date','item','item_type','item_sub_type']], axis=1, inplace=True)

    ###Standardize the variable
    from sklearn.preprocessing import StandardScaler 
    df['activity_type'] = df['activity_type'].factorize()[0]
    scaler = StandardScaler()
    scaler.fit(df.drop(['activity_type'],axis=1))
    scaled_features = scaler.transform(df.drop('activity_type',axis=1))
    df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])

    ### View of dataset after dropping and factorizing columns
    st.write("Dataset")
    st.write(df_feat)

    list_var = df_feat.columns

    ### The st.multiselect() function creates a multiselect dropdown menu that allows users to select the explanatory variables.
    output_multi = st.multiselect("Select Explanatory Variables", list_var, default=['money_earned','rp_earned','kills','deaths','suicides','time_spent'])

    new_df2 = df_feat[output_multi]
    x = new_df2
    y = df['activity_type']

    ## The train_test_split() function splits the data into training and testing sets.
    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=test_size)
    
    from sklearn.neighbors import KNeighborsClassifier
    knn = KNeighborsClassifier(n_neighbors=n_number)
    knn.fit(X_train,y_train)
    y_pred = knn.predict(X_test)
    from sklearn.metrics import classification_report,confusion_matrix
    st.write(classification_report(y_test,y_pred))

    ### The st.columns() function creates 3 columns to display the feature columns and target column.
    col1,col2 = st.columns(2)
    col1.subheader("Variables used")
    col1.write(X_test.head(10))
    col2.subheader("Selling price comparision")

    ###Concat 2 columns, covert predictions type from array to df
    df_pred = pd.concat([pd.DataFrame(y_pred),y_test],ignore_index=True,axis=1) 
    df_pred.columns = ['Prediction','Real data']
    col2.write(df_pred.head(10))

    ### The st.subheader() function creates a subheading for the results section.
    st.subheader('üéØ Results')
    st.write("The Accuracy score of model is:", np.round(mt.accuracy_score(y_test, y_pred),2))

